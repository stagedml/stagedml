BERT fine-tuning experiments
============================

In this report we show various aspects of BERT fine-tuning on GLUE dataset using
[StagedML](https://github.com/stagedml/stagedml) domain-specific language. This
document is a literate Python program rendered with the CodeBraid processor.

```{.python .cb.nb}
from bert_finetune_experiment import *
import altair as alt
import pandas as pd
```

See also:

* [Bert-finetune project](/run/bert_finetune) in the StagedML source tree.
* [bert_pretrain_experiment.py](../bert_finetune_experiment.py) utilities.

Contents
--------

1. [Fine-tuning on GLUE tasks](#fine-tuning-on-glue-tasks)
2. [Batch size in BERT->MRPC fine-tuning](#batch-size-in-bert-mrpc-fine-tuning)
3. [Learning rate in BERT->MRPC fine-tuning](#learning-rate-in-bert-mrpc-fine-tuning)

Fine-tuning on GLUE tasks
-------------------------

In this section we fine-tune BERT-mini model on most of GLUE tasks in a loop.
For some tasks, we amend the batch size. We also amend values of `batch_size`
and epoches for some tasks.

### Definitions

```{.python .cb.code
    include_file=bert_finetune_experiment.py
    include_regex="def experiment_allglue.*return result_allglue"}
```

```{.python .cb.nb show=stdout:raw+stderr}
p=join(environ.get('REPIMG',environ['REPOUT']),"graph.png")
stage=partial(all_minibert_finetune_glue,task_name='QQP')
depgraph([stage],filename=p)
print(f"![]({p})")
```

* We loop over all GLUE tasks excluding COLA (TODO: remember why do we exclude
  COLA?)
* For every task, we realize minibert model
  - `realizeMany(instantiate(...))` is the generic procedure of realizing
    Pylightnix stages
  - `redefine(..)` allows us re-define stage's configuration in-place. In our
    case we adjust parameters to match the upstream settings (set `batch_size`,
    4 epoch)
  - Note, that we don't evaluate all possible parameters like the upstream did
    due to time/hardware constraints.
  - `all_minibert_finetune_glue` is defined in `stagedml.stages.all`. By
    realizing it we also realize all it's dependencies, which includes fetching
    the required checkpoints and datasets.
* We build a dictionary containing `RRef` realization reference for every task.
* We also display a graph of stages to be realized in order to realize the
  top-level stage of `all_minibert_finetune_glue(task_name='QQP')`:
* The url of pre-trained model image:
  `markdown_url(mklens(instantiate(stage).dref).refbert.url.val)`{.python .cb.expr}

### Results

```{.python .cb.nb show=code}
results=experiment_allglue()
```

```{.python .cb.nb show=code+stdout:raw+stderr}
t=BeautifulTable(max_width=1000)
t.set_style(BeautifulTable.STYLE_MARKDOWN)
t.width_exceed_policy = BeautifulTable.WEP_ELLIPSIS
t.column_headers=['Name']+list(results.keys())
t.append_row(['Accuracy, %']+[
  100*protocol_rref_metric(results[tn][0],'evaluate','eval_accuracy')
    for tn in results.keys()])
t.append_row(['F1_score*100']+[
  100*protocol_rref_metric(results[tn][0],'evaluate','f1_score')
    for tn in results.keys()])
t.append_row(['Tr.time, min']+[f"{store_buildelta(rrefs[0])/60:.1f}"
                                  for rrefs in list(results.values())])
print(t)
```

Where:

* `Tr.time` shows training time in seconds, training was done on a single NVidia
  1080Ti GPU.
* See also [reference results by Google
  Research](https://github.com/google-research/bert#bert).

Batch size in BERT->MRPC fine-tuning
------------------------------------

In this section we study how does `batch_size` affect final accuracy of the
model.

### Definitions

```{.python .cb.code
    include_file=bert_finetune_experiment.py
    include_regex="def experiment_bs.*return result_bs"}
```

* We loop over certain batch_sizes and evaluate BERT-mini fine-tuning procedure.
  List of important APIs includes:
  - `realizeMany(instance(..))` runs generice two-pass stage realization
    mechanism of Pylightnix.
  - `redefine(..)` tweaks stage configuration before the realization. Besides
    setting batch_size, we increase number of epoches up to 5.
  - `all_minibert_finetune_glue` is one of StagedML stages, defined in
    `stagedml.stages.all`. By realizing it we also realize all it's
    dependencies, which includes fetching the required images and datasets from
    the Internet.
* `num_instances` parameter of `all_minibert_finetune_glue` stage sets the
  desired number of model instances sharing the same configuration.
* We collect results in a dictionary which maps `batch_sizes` to corresponding
  realization references.

### Results

```{.python .cb.nb show=code}
results=experiment_bs()
```

```{.python .cb.nb show=code+stdout:raw+stderr}
cols={'eval_accuracy':[], 'batch_size':[], 'attempt':[]}
for bs,rrefs in results.items():
  for attempt,rref in enumerate(rrefs):
    es=tensorboard_tensors(rref, 'eval', 'eval_accuracy')
    cols['eval_accuracy'].extend([100.0*te2float(e) for e in es])
    cols['batch_size'].extend([bs for _ in es])
    cols['attempt'].extend([attempt for _ in es])
chart=alt.Chart(pd.DataFrame(cols)).mark_point().encode(
  x=alt.X('batch_size', title='Batch size'),
  y=alt.Y('eval_accuracy', title='Evaluation accuracy, %',
                           scale=alt.Scale(zero=False)),
  color='attempt:O')
altair_print(chart, f'figure_eval_accuracy.png')
```

```{.python .cb.nb show=code+stdout:raw+stderr}
cols={'nexamples':[], 'valid_accuracy':[], 'batch_size':[], 'attempt':[]}
for bs,rrefs in results.items():
  for attempt,rref in enumerate(rrefs):
    es=tensorboard_tensors(rref,'valid','accuracy')
    cols['nexamples'].extend([e.step*bs for e in es])
    cols['valid_accuracy'].extend([100.0*te2float(e) for e in es])
    cols['batch_size'].extend([bs for _ in es])
    cols['attempt'].extend([attempt for _ in es])
chart=alt.Chart(pd.DataFrame(cols)).mark_line(point=True).encode(
  x=alt.X('nexamples', title='Training examples seen by the model'),
  y=alt.Y('valid_accuracy', title='Validation accuracy, %',
                            scale=alt.Scale(zero=False)),
  color='batch_size:O',
  strokeDash='attempt:O')
altair_print(chart, f'figure_valid_accuracy.png')
```

* `tensorboard_tensors` is a helper method which access stages tensorboard
  journals stored in realization folder.
* `attempt` is the identifier of the training attempt. For any given
  `batch_size`, attempts differ only with the initial values of classification
  head of the model.
* `batch_size` is the batch size used during fine-tuning
* `steps` is the number of sentences passed through the model. According to the
  value of `max_seq_length` parameter, each sentence contains maximum 128
  tokens.
* TODO: find out why do models with smaller batch sizes train better?
  - Is it the effect of batch-normalization?
  - Is it the effect of un-disabled dropout?


Learning rate in BERT->MRPC fine-tuning
---------------------------------------

### Definitions

```{.python .cb.code
    include_file=bert_finetune_experiment.py
    include_regex="experiment_lr.*return result_lr"}
```

### Results

```{.python .cb.nb show=code}
results=experiment_lr()
```

```{.python .cb.nb}
cols={'learning_rate':[], 'eval_accuracy':[], 'attempt':[]}
for lr_,rrefs in results.items():
  lr=float(lr_)
  for iid,rref in enumerate(rrefs):
    es=tensorboard_tensors(rref,'eval','eval_accuracy')
    cols['eval_accuracy'].extend([te2float(e) for e in es])
    cols['learning_rate'].extend([lr for _ in es])
    cols['attempt'].extend([iid for _ in es])
```

```{.python .cb.nb show=code+stdout:raw+stderr}
chart=alt.Chart(pd.DataFrame(cols)).mark_point().encode(
  x='learning_rate',
  y=alt.Y('eval_accuracy', title='Evaluation accuracy, %',
                            scale=alt.Scale(zero=False)),
  color='attempt:O')
altair_print(chart, f'figure_eval_accuracy_lr.png')
```

