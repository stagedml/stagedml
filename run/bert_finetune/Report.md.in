BERT fine-tuning experiments
============================

```{.python .cb.nb}
import altair as alt
import pandas as pd
import numpy as np
from bert_finetune_experiment import *
from stagedml.stages.all import *
```


Fine-tuning on GLUE tasks
-------------------------

```{.python .cb.code
    include_file=bert_finetune_experiment.py
    include_regex="experiment_allglue.*return result_allglue"}
```

Here, we:

* Loop over all tasks excluding COLA (TODO: remember why do we exclude COLA?)
* For every task, we realize minibert model
  - `realizeMany(instantiate(...))` is the generic procedure of realizing
    Pylightnix stages
  - `redefine(..)` allows us re-define stage's configuration in-place. In our
    case we adjust parameters to match the upstream settings (set `batch_size`,
    4 epoch)
  - Note, that we don't evaluate all possible parameters like the upstream did
    due to time/hardware constraints.
  - `all_minibert_finetune_glue` is one of StagedML stages, defined in
    `stagedml.stages.all`. By realizing it we also realize all it's
    dependencies, which includes fetching the required images and datasets from
    the Internet.
* We build a dictionary containing `RRef` realization reference for
  every task.

```{.python .cb.nb show=code}
results=experiment_allglue()
```

We display results in a table

```{.python .cb.nb show=code+stdout:raw+stderr}
t=BeautifulTable(max_width=1000)
t.set_style(BeautifulTable.STYLE_MARKDOWN)
t.width_exceed_policy = BeautifulTable.WEP_ELLIPSIS
t.column_headers=['Name']+list(results.keys())
t.append_row(['Accuracy, %']+[
  100*protocol_rref_metric(results[tn][0],'evaluate','eval_accuracy')
    for tn in results.keys()])
t.append_row(['F1_score*100']+[
  100*protocol_rref_metric(results[tn][0],'evaluate','f1_score')
    for tn in results.keys()])
t.append_row(['Tr.time, min']+[f"{store_buildelta(rrefs[0])/60:.1f}"
                                     for rrefs in list(results.values())])
print(t)
```

Ref. [Upstream results](https://github.com/google-research/bert#bert)

Batch size in BERT->MRPC fine-tuning
------------------------------------

The top-level procedure of the experiment:

```{.python .cb.code
    include_file=bert_finetune_experiment.py
    include_regex="experiment_bs.*return result_bs"}
```

In the above code we:

* Loop over certain batch_sizes. For every batch_size we evaluate min-bert model
  - `realizeMany(instance(..))` runs generice two-pass stage realization
    mechanism of Pylightnix.
  - `redefine(..)` tweaks stage configuration before the realization. Besides
    setting batch_size, we increase number of epoches up to 5.
  - `all_minibert_finetune_glue` is one of StagedML stages, defined in
    `stagedml.stages.all`. By realizing it we also realize all it's
    dependencies, which includes fetching the required images and datasets from
    the Internet.
* In a version of this experiment we could increase a number stages instances
  which shares same configuration by setting `num_instances`.
* We collect resulting realization references in a dictionary.

```{.python .cb.nb show=code}
results=experiment_bs(exclude=['+f1v2'])
```

Results are shown below.

```{.python .cb.nb}
dfs=[]
for bs,rrefs in results.items():
  for iid,rref in enumerate(rrefs):
    cols={}
    es=tensorboard_tensor_events(rref,'valid','accuracy')
    assert len(es)>0
    cols['steps']=[e.step*bs for e in es]
    cols['valid_accuracy']=[te2float(e) for e in es]
    cols['batch_size']=[bs for _ in es]
    cols['iid']=[iid for _ in es]
    es=tensorboard_tensor_events(rref,'valid','loss')
    assert len(cols['steps'])==len(es)
    cols['valid_loss']=[te2float(e) for e in es]
    dfs.append(DataFrame(cols))
ds=pd.concat(dfs)
```

Comments:

* `tensorboard_tensor_events` is a helper method which access stages tensorboard
  journals stored in realization folder.
* `iid` is the instance identifier of the model.
* `batch_size` is the batch size used during fine-tuning
* `steps` is the number of sentences passed through the model. According to the
  value of `max_seq_length` parameter, each sentence contains maximum 128
  tokens.

```{.python .cb.nb show=code+stdout:raw+stderr}
metric='valid_accuracy'
chart=alt.Chart(ds).mark_line().encode(
  x='steps', y=metric, color='batch_size',
  strokeDash='iid')
altair_print(chart, f'figure_{metric}.png')
```

* TODO: find out why do models with smaller batch sizes train better?
  - Is it the effect of batch-normalization?
  - Is it the effect of un-disabled dropout?

Junk
----

```
{.python .cb.nb show=code+stdout:raw+stderr}
metric='train-lr'
dflist=results[metric]
df=pd.concat(dflist)
df=df[(df['batch_size']==32) | (df['batch_size']==2)]
chart=alt.Chart(df).mark_line().encode(
  x='step', y='value', color='batch_size',
  strokeDash='optver')
altair_print(chart, f'figure_{metric}.png')
```

